# Подпотоки и контрольные IP

Итак, мы дошли до компонента `Collate`, упомянутого в предыдущей главе. В этой будет показано, как комбинировать `Collate`, подпотоки и контрольные IP для решения одного из самых сложных типов традиционных "пакетных" бизнес-приложений. Основная функция `Collate`, как и [раскладочно-подборочной машины](https://en.wikipedia.org/wiki/Unit_record_equipment#Collating), от которой она получила свое название, состоит в объединении IP из входящих потоков на основе значений в "ключевых полях" (определение этих полей обычно указывается в IP опций). В большинстве приложений есть более одного такого поля, которое используется для указания различных уровней группировки. В качестве примера возьмем файл с банковскими счетами по нескольким филиалам. Номера счетов могут быть неуникальными между разными филиалами. Другими словами, чтобы сделать номер счета уникальным для всего банка, мы должны указать номер филиала.

Допустим, у нас есть приложение, в котором поток банковских транзакций должен течь с потоком счетов: сперва мы сортируем оба потока по номеру счета в номере филиала. В обычном программировании мы должны написать программу типа "Обновление". Как-то я подсчитал, что около четверти всех бизнес-приложений сегодня — это обновления! Независимо от того, верна ли эта цифра, программы обновлений трудно писать и ещё труднее модифицировать, а единственная помощь, которую получают программисты — лист бумаги, передаваемый от отца к сыну, поясняющий основную логику обновлений, которая представляет собой паттерн движений и сравнений, обычно называемый техникой «линии баланса». Затем эту логику необходимо вручную изменить, чтобы она соответствовала конкретной ситуации, с которой вы столкнулись. Тем не менее, это всего лишь описание подхода — чтобы адаптировать его к конкретному приложению, вы должны его серьёзно модифицировать. Однажды я имел сомнительное удовольствие править такую программу, автор которой написал клиенту объяснение, почему его просьба не может быть удовлетворена, которая начиналась так: «Из-за ограничений обработки данных...». Мое ясное воспоминание, по прошествии почти 25 лет, о модификации этой программы (а для традиционно запрограммированной программы она была действительно хорошо написана) - это было не то что бы **совершенно** невозможно!

(Прим. Пер. - К сожалению, Пол не проиллюстрировал эти входные потоки в виде таблицы).

А теперь представьте, что вы могли бы сделать, если бы у вас был заранее написанный, предварительно протестированный компонент для сопоставления потоков данных. Давайте представим, что у нас есть поток транзакций и поток счетов, отсортированных по номеру счета в филиале. Теперь мы объединим их в один поток, указав номер филиала и номер счета в качестве основного и дополнительного контрольных полей соответственно. Когда `Collate` находит две одинаковые записи из двух разных порт-элементов, он сначала выводит запись из элемента с наименьшим номером. Результирующий выходной поток будет содержать следующий шаблон:

(Прим. Пер. - судя по всему, одна строка в таблице представляет один IP, а колонки `branch` и `acct` являются теми самыми "ключевыми полями").

```
IP type     branch   acct #      date       amount   DEP/WD

account        1        1
trans          1        1      1992/3/12     12.82     DEP
trans          1        1      1992/3/12    101.99     WD
trans          1        1      1992/3/12     43.56     WD
trans          1        1      1992/3/26     54.77     WD
trans          1        1      1992/3/26     12.26     WD

account        1        2
trans          1        2      1992/3/03     34.88     DEP
trans          1        2      1992/3/03     10.00     WD
.
.
.

account        2        1
trans          2        1      1992/2/29     25.99     DEP
trans          2        1      1992/3/25     87.56     DEP

account        2        3
trans          2        3      1992/3/01     34.88     WD
trans          2        3      1992/3/17     88.22     DEP
.
.
```

Смотрите как `Collate`, работающий с отсортированными входными потоками, дает нам хорошо упорядоченный и сгруппированный поток данных на выходе, состоящий из двух типов IP с данными. Работа процесса, следующего за `Collate`, намного проще, чем обычная "линия баланса", которая должна выполнять эту группировку, а также реализовывать необходимую бизнес-логику. Обычное "обновление" также должно беспокоиться о том, что произойдет, если один файл кончится раньше другого. Вместо этого в нашем FBP-решении фактическая бизнес-логика (по сравнению с логикой синхронизации двух файлов) видит один IP за раз, определяет его тип и решает, что с ним делать. В дальнейшем мы будем называть этот процесс `UPDATE_ACCTS`. Одно из практических правил традиционного программирования состоит в том, что сложность программы примерно пропорциональна квадрату числа входных файлов. Таким образом, всего один повторно используемый `Collate` уже может значительно упростить `UPDATE_ACCTS`!

До сих пор мы говорили об уровнях филиала и счёта. Теперь давайте предположим, что мы хотим сгруппировать транзакции по дате — банковские выписки часто показывают только один промежуточный итог в день. Это дает нам уже 3 уровня группировки, большая часть которых распознаются только по изменениям в контрольных полях. Изменение номера счёта можно узнать по прибытию нового IP счёта (аккаунта), но это не говорит нам, когда пошёл новый филиал. Таким образом, большая часть логики в традиционном обновлении привязана к изменениям значений контрольных полей. `Collate` в любом случае должен просматривать все значения контрольных полей, поэтому было бы неплохо, если бы мы могли позволить `Collate` определять группы и передавать эту информацию нижестоящим процессам, которые, таким образом, были бы освобождены от всего этого сравнения, чтобы увидеть, когда конкретная группа начинается или заканчивается. Как `Collate` передает эту группирующую информацию вниз по течению? Ты угадал! Мы используем «скобочные» IP, упомянутые в главе 3.

IP-скобки имеют распознаваемый тип, который следует специальному соглашению, поэтому они никогда не могут конфликтовать с типами, определенными пользователем. Скобки бывают двух видов: открывающие и закрывающие. Они также могут содержать реальные данные (если длина их IP не равна нулю), которые по соглашению мы используем для имени группы, которую они ограничивают. Давайте заставим `Collate` вставить несколько скобок в выходной поток, в результате чего поток сопоставленных данных будет выглядеть, как показано на следующей диаграмме. Как и прежде, я буду использовать символы `<` и `>` для представления IP открытой и закрытой скобок, но на этот раз мы покажем имена групп, на которые они ссылаются в своей области для данных (`date` означает группу, включающую все внесения и снятия средств за определенную дату). Чтобы было немного понятнее, я покажу "номер уровня" `L` перед каждым IP - открытые скобки увеличивают его, закрытые скобки уменьшают. Я просто покажу первые несколько IP собранного потока:

```
L  IP type     branch    acct #     date     amount   DEP/WD

0 |< 		   branch
1 |< 		   account
2 |account          1        1
2 |< 		   date
3 |trans            1        1    1992/3/12    12.82    DEP
3 |trans            1        1    1992/3/12   101.99    WD
3 |trans            1        1    1992/3/12    43.56    WD
3 |> 		   date
2 |< 		   date
3 |trans            1        1    1992/3/26    54.77    WD
3 |trans            1        1    1992/3/26    12.26    WD
3 |> 		   date
2 |> 		   account
1 |< 		   account
2 |account          1        2
2 |< 		   date
3 |trans            1        2    1992/3/03    34.88    DEP
3 |trans            1        2    1992/3/03    10.00    WD
2 |> 		   date
```

Как правило, логика `UPDATE_ACCTS` будет состоять из оператора `case`, основанного на типе входящего IP. Открытая скобка заставит текущие `counters` и `totals` для текущего уровня проинициализировать нулями; закрывающая скобка приведет к отправке IP, содержащего `counters` и `totals` для этого уровня, на выходной порт. Нам даже не придется повторно инициализировать `counters` и `totals` на этом этапе, поскольку мы знаем, что вскоре появится еще одна открытая скобка (или `end of data`). Мы могли бы либо обновлять `counters` и `totals` на каждом уровне для каждого входного IP, либо просто "катить" (Прим.Пер. - сохранять?) значения на следующий уровень в момент прихода закрытой скобки — кажется, проще последнее. В структуре данных есть некоторая избыточность, поскольку IP счёта всегда предшествует открытая скобка счёта, но это избыточность данных лучше, чем их нехватка! Поскольку нам потребуется информация с IP счёта, мы можем просто проигнорировать открытую скобку счёта, или мы можем сделать перекрестную проверку, что оба присутствуют.

Так что вот основная часть логики `UPDATE_ACCTS` (процесс ниже по потоку от `Collate`) выглядит примерно так:

```
receive incoming IP
    begin cases based on IP type
        case: open bracket for branch
            initialize counters and totals for branch
        case: open bracket for account
            initialize counters and totals for account
        case: open bracket for date
            initialize counters and totals for date

        case: account
            pick up account info
        case: transaction
            increment counter for debit or credit
            add amount to debit or credit total

        case: close bracket for date
            output IP containing counters and totals for
                date
            roll these values to account level
        case: close bracket for account
            output IP containing counters and totals for
                account
            roll these values to branch level
        case: close bracket for branch
            output IP containing counters and totals for
                branch
   end cases
```

Фигура 9.3

<!-- CHECK FROM HERE -->

Обратите внимание, как эти группы идеально «вложены», и в любой момент времени мы смотрим только на один уровень или максимум на два соседних. Мы могли бы очень элегантно обрабатывать такую логику, используя стек push-down или LIFO. Помните, что это структура данных, которая растёт и убывает только с одного конца. Мы также должны решить, в какой структуре данных будут храниться все эти `counters` и `totals`. Одним из вариантов мог бы быть массив, но для каждого уровня мы должны в конечном итоге вывести IP, содержащий значения для этого уровня, так почему бы не хранить значения в IP все время? _Этот тип IP называется контрольным IP_, и его можно описать как **IP, время жизни которого точно соответствует времени жизни подпотока**, который он, можно сказать, «представляет».

Теперь мы можем объединить эти методы и сделать вывод, что будем работать со стеком, содержащим контрольные IP (на самом деле их дескрипторы). Таким образом, приведенная выше логика становится намного проще. Теперь она читается примерно так:

```
receive incoming IP
    begin cases based on IP type
        case: open bracket
            create IP for this level
            initialize counters and totals for this level
            push IP onto stack

        case: account
            pick up account info, insert into account IP

        case: transaction
            increment counter for debit or credit in IP
                currently at head of stack
            add amount to debit or credit total in IP
                currently at head of stack

        case: close bracket
            pop IP off stack
            roll counters and totals in this IP into IP
                currently at top of stack, if there is one
            output IP which was just popped off stack
    end cases
```

Фигура 9.4

Когда мы говорим «создать IP» в приведенной выше логике, мы можем просто использовать входящий IP, если в начале группы есть характерный тип. Имейте в виду, однако, что IP должен иметь поля данных для totals. Самый очевидный метод — создать контрольный IP, скопировать поля, такие как идентификаторы, из входящего IP (часто это тот, что идёт после открытой скобки) в контрольный IP, сохранить контрольный IP и отбросить исходный входящий IP. Однако более быстрый метод, который иногда можно использовать, заключается в том, чтобы входящие данные помещались в более крупный IP в то время, когда они считываются приложением. Затем его можно сразу сложить, без утомительной последовательности «создать новый, скопировать, уничтожить старый».

Теперь, когда у нас есть контрольные IP, что мы будем использовать в качестве стека? В AMPS был механизм стека специально для такой логики, который на самом деле был своего рода соединением (которое было присоединено только к одному концу, как [cul de sac](<https://en.wikipedia.org/wiki/Dead_end_(street)>) в городе). В более поздних версиях DFDM не было механизмов стека, но, поскольку мы имеем дело только с одним компонентом, было достаточно просто настроить массив дескрипторов IP в рабочей памяти процесса, а также "пушить" и "попать" (базовые операции со [стеком](<https://en.wikipedia.org/wiki/Stack_(abstract_data_type)>)) путем увеличения или уменьшения индекса массива. Однако мне нравятся стеки, и в следующей главе _мы увидим поразительное сходство между тем, как компоненты анализируют свои входные потоки, и тем, как компиляторы анализируют свои входные данные_ - в обоих случаях **стеки являются естественным механизмом отслеживания вложенных структур**. Соответственно, мы предоставили механизм стека в THREADS.

Вы, возможно, заметили, что на рисунках `9.3` и `9.4` не было знакомого «do while receive has not reached end of data» — это потому, что они написаны в стиле, который предполагает, что они завершают выполнение после обработки каждого IP. В FBP неактивный процесс будет вызываться в следующий раз, когда IP прибывает на любой из его входных портов, поэтому этот тип компонента будет вызываться один раз для каждого входящего IP. Как следствие, он не может поддерживать непрерывность между несколькими IP, но здесь на сцену и выходит стек. **Поскольку стек находится за пределами локального хранилища процесса, непрерывность может поддерживаться при вызовах с использованием стека**. Этот стиль компонента называется «non-looper», в отличие от компонентов, написанных в стиле «do while receive has not reached end of data», которые называются "loopers". Это не определяемый извне атрибут компонента, это зависит от того, когда и как часто компонент решает завершить обработку — до тех пор, пока есть данные для обработки, они будут продолжать вызываться повторно.

Вам может быть интересно, каковы преимущества non-loopers, если таковые имеются. Ну, во-первых, non-loopers завершают выполнение чаще, поэтому IP, которые не были отброшены или удалены, обнаруживаются раньше, что облегчает поиск таких ошибок. Кроме того, локальное хранилище non-loopers используется только в рамках одного вызова, поэтому у логики одного IP меньше возможностей мешать логике другого. Также мы увидим в главе о чекпойнтах (глава 20), что есть преимущество в том, чтобы процессы передавали управление как можно чаще. Как всегда есть плюсы и минусы.

Очевидно, что для `UPDATE_ACCTS` еще нужно написать некоторую логику приложения, но я попытался показать, что подход с хранением управляющих IP в стеке (вместе с обобщенной сортировкой) значительно упрощает оставшуюся часть логики, которую вам нужно записывать. Одной из вещей, которая также упрощает эту логику, является тот факт, что каждое действие связано с приходом определенного типа IP (это еще более очевидно в случае non-loopers), а не с изменением значения - это это то, что позволяет разбить логику такого компонента на отдельные кейсы. Говоря о такой логике, я часто считаю полезным ссылаться на «время открытых скобок» или «время детализации». Входящий IP запускает действие, которое выполняется, а затем завершается, подготавливая процесс к приходу следующего IP (или к концу данных). В одной из последующих глав я попытаюсь показать, что код, который нам еще предстоит написать, имеет настолько простую структуру, что мы можем начать думать о его полуавтоматической генерации из какой-либо спецификации, отличной от программы на языке HLL.

Кстати, когда вы работаете с такой логикой, вы можете заметить характерный привкус FBP: очень небольшая часть данных, с которыми вы будете иметь дело, на самом деле находится в рабочем хранилище процесса — подавляющее большинство из них будет в IP, очень часто в контрольных IP, подобных тем, что мы только что обсуждали. Это не должно казаться странным — в реальном офисе большая часть ваших данных находится в файлах, заметках или на компьютере — сколько данных вы должны хранить в своей голове? Не знаю, как вы, а я стараюсь хранить как можно меньше и в течение как можно более короткого времени (после чего я их уничтожаю, передаю или архивирую — так же, как и IP).
