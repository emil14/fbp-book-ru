# Подпотоки и контрольные IP

Теперь мы дошли до компонента `Collate`, упомянутого в предыдущей главе. В этой главе также будет показано, как можно комбинировать `Collate`, подпотоки и контрольные IP для решения одного из самых сложных типов обычных пакетных бизнес-приложений. Основная функция `Collate`, как и машины [Collator Unit Record](https://en.wikipedia.org/wiki/Unit_record_equipment#Collating), от которой она получила свое название, состоит в объединении IP в своих входящих потоках данных на основе значений в ключевых полях (определение этих полей обычно указывается в IP опций). В большинстве приложений у нас есть более одного ключевого поля, которые используются для указания различных уровней группировки. В качестве примера возьмем файл банковских счетов в филиалах. В этом конкретном банке мы скажем, что номера счетов не обязательно будут уникальными в разных филиалах. Другими словами, чтобы сделать номер счета уникальным для всего банка, мы должны указать номер отделения.

Предположим, у нас есть приложение, в котором поток банковских транзакций должен течь против потока записей счетов: сначала мы сортируем оба потока по номеру счета в номере филиала. В обычном программировании мы должны написать программу «Обновление». Однажды я подсчитал, что около четверти всех бизнес-программ, запущенных сегодня, — это обновления! Независимо от того, верна ли эта цифра, но программы обновлений трудно кодировать и труднее модифицировать, и все же единственная помощь, которую когда-либо получали программисты, — это лист бумаги, передаваемый от отца к сыну, показывающий основную логику обновлений, которые представляет собой паттерн движений и сравнений, обычно называемый техникой «линии баланса». Затем эту логику необходимо изменить вручную, чтобы она соответствовала конкретной ситуации, с которой вы столкнулись. Тем не менее, это всего лишь описание подхода — чтобы адаптировать его к конкретному приложению, вы должны его серьёзно модифицировать. Однажды я имел сомнительное удовольствие модифицировать программу обновления, автор которой написал клиенту объяснение, почему его просьба не может быть удовлетворена, которая начиналась так: «Из-за ограничений обработки данных...» Мое ясное воспоминание, по прошествии почти 25 лет о модификации этой программы (а для традиционно запрограммированной программы она была действительно хорошо написана) -
это не было **совершенно** невозможно!

А теперь представьте, что вы могли бы сделать, если бы у вас был заранее написанный, предварительно протестированный компонент для сопоставления потоков данных. Давайте представим, что у нас есть поток транзакций и поток счетов, отсортированных по номеру счета в филиале. Теперь мы объединим их в один поток, указав номер филиала и номер счета в качестве основного и дополнительного контрольных полей соответственно. Когда `Collate` находит две одинаковые записи из двух разных порт-элементов, он сначала выводит запись из элемента с наименьшим номером. Результирующий выходной поток будет содержать следующий шаблон:

```
IP type     branch   acct #      date       amount   DEP/WD

account        1        1
trans          1        1      1992/3/12     12.82     DEP
trans          1        1      1992/3/12    101.99     WD
trans          1        1      1992/3/12     43.56     WD
trans          1        1      1992/3/26     54.77     WD
trans          1        1      1992/3/26     12.26     WD

account        1        2
trans          1        2      1992/3/03     34.88     DEP
trans          1        2      1992/3/03     10.00     WD
.
.
.

account        2        1
trans          2        1      1992/2/29     25.99     DEP
trans          2        1      1992/3/25     87.56     DEP

account        2        3
trans          2        3      1992/3/01     34.88     WD
trans          2        3      1992/3/17     88.22     DEP
.
.
```

Обратите внимание, что действие `Collate`, работающего с отсортированными входными потоками, дает нам хорошо упорядоченный и сгруппированный поток данных на выходе, состоящий из двух типов данных IP. Таким образом, работа процесса, следующего за `Collate`, намного проще, чем обычная Balance Line, которая должна выполнять эту группировку, а также реализовывать необходимую бизнес-логику. Обычное обновление также должно беспокоиться о том, что произойдет, если один файл кончится раньше другого. Вместо этого в нашем FBP-решении фактическая бизнес-логика (по сравнению со всей логикой синхронизации двух файлов данных) видит один IP за раз, определяет его тип и решает, что с ним делать. В дальнейшем мы будем называть этот процесс `UPDATE_ACCTS`. Одно из практических правил традиционного программирования состоит в том, что сложность программы примерно пропорциональна квадрату числа входных файлов. Таким образом, всего один повторно используемый компонент, `Collate`, может значительно упростить `UPDATE_ACCTS`!

До сих пор мы говорили об уровнях филиала и аккаунта. Теперь давайте предположим, что мы хотим сгруппировать транзакции по дате — банковские выписки часто показывают только один промежуточный итог в день. Это дает нам три уровня группировки, большинство из которых распознаются только по изменениям в контрольных полях. Изменение номера учетной записи можно узнать по прибытию нового IP учетной записи, но это не может сказать нам, когда начался новый филиал. Таким образом, большая часть логики в традиционном обновлении привязана к изменениям значений контрольных полей. `Collate` в любом случае должен просматривать все значения контрольных полей, поэтому было бы неплохо, если бы мы могли позволить `Collate` определять группы и передавать эту информацию нижестоящим процессам, которые, таким образом, были бы освобождены от всего этого сравнения, чтобы увидеть, когда конкретная группа начинается или заканчивается. Как `Collate` передает эту группирующую информацию вниз по течению? Ты угадал! Мы используем «скобочные» IP, упомянутые в главе 3.

IP-скобки имеют распознаваемый тип, который следует специальному соглашению, поэтому они никогда не могут конфликтовать с типами, определенными пользователем. Скобки бывают двух видов: открывающие и закрывающие. Они также могут содержать реальные данные (если длина их IP не равна нулю), которые по соглашению мы используем для имени группы, которую они ограничивают. Давайте заставим `Collate` вставить несколько скобок в выходной поток, в результате чего поток сопоставленных данных будет выглядеть, как показано на следующей диаграмме. Как и прежде, я буду использовать скобки для представления IP с открытой и закрытой скобками, но на этот раз мы покажем имена групп, к которым они относятся, в части данных IP скобки («дата» означает группу, включающую все внесения и снятия средств на определенную дату). Чтобы было немного понятнее, я покажу "номер уровня" (L) перед каждым IP - открытые скобки увеличивают его, закрытые скобки уменьшают). Я просто покажу первые несколько IP собранного потока:

```
L  IP type     branch    acct #     date     amount   DEP/WD

0 |< 		   branch
1 |< 		   account
2 |account          1        1
2 |< 		   date
3 |trans            1        1    1992/3/12    12.82    DEP
3 |trans            1        1    1992/3/12   101.99    WD
3 |trans            1        1    1992/3/12    43.56    WD
3 |> 		   date
2 |< 		   date
3 |trans            1        1    1992/3/26    54.77    WD
3 |trans            1        1    1992/3/26    12.26    WD
3 |> 		   date
2 |> 		   account
1 |< 		   account
2 |account          1        2
2 |< 		   date
3 |trans            1        2    1992/3/03    34.88    DEP
3 |trans            1        2    1992/3/03    10.00    WD
2 |> 		   date
```

Как правило, логика `UPDATE_ACCTS` будет состоять из оператора `case`, основанного на типе входящего IP. Открытая скобка заставит текущие counters и totals для текущего уровня проинициализировать нулями; закрывающая скобка приведет к отправке IP, содержащего counters и totals для этого уровня, на выходной порт. Нам даже не придется повторно инициализировать counters и totals на этом этапе, потому что мы знаем, что вскоре появится еще одна открытая скобка (или end of data). Мы могли бы либо обновлять counters и totals на каждом уровне для каждого IP входящих данных, либо просто перекатывать значения на следующий уровень вверх в момент прихода закрытой скобки — кажется, что проще выбрать последнее. В структуре данных есть некоторая избыточность, поскольку IP учетной записи всегда предшествует открытая скобка учетной записи, но это намного лучше, чем нехватка данных! Поскольку нам потребуется информация с IP учетной записи, мы можем просто проигнорировать открытую скобку учетной записи, или мы можем сделать перекрестную проверку, чтобы они оба присутствовали.

Пока основная часть логики для `UPDATE_ACCTS` (процесс ниже по потоку от `Collate`) выглядит примерно так:

```
receive incoming IP
    begin cases based on IP type
        case: open bracket for branch
            initialize counters and totals for branch

        case: open bracket for account
            initialize counters and totals for account

        case: open bracket for date
            initialize counters and totals for date

        case: account
            pick up account info

        case: transaction
            increment counter for debit or credit
            add amount to debit or credit total

        case: close bracket for date
            output IP containing counters and totals for
                date
            roll these values to account level

        case: close bracket for account
            output IP containing counters and totals for
                account
            roll these values to branch level

        case: close bracket for branch
            output IP containing counters and totals for
                branch
   end cases
```

Фигура 9.3

Обратите внимание, эти группы идеально «вложены», и в любой момент времени мы смотрим только на один уровень или максимум на два соседних. Мы могли бы очень элегантно обрабатывать такую логику, используя стек push-down или LIFO. Помните, что это структура данных, которая растёт и убывает только с одного конца. Мы также должны решить, в какой структуре данных будут храниться все эти counters и totals. Одним из вариантов мог бы быть массив, но для каждого уровня мы должны в конечном итоге вывести IP, содержащий значения для этого уровня, так почему бы не хранить значения в IP все время? _Этот тип IP называется контрольным IP_, и его можно описать как **IP, время жизни которого точно соответствует времени жизни подпотока**, который он, можно сказать, «представляет».

Теперь мы можем объединить эти методы и сделать вывод, что будем работать со стеком, содержащим контрольные IP (на самом деле их дескрипторы). Таким образом, приведенная выше логика становится намного проще. Теперь она читается примерно так:

```
receive incoming IP
    begin cases based on IP type
        case: open bracket
            create IP for this level
            initialize counters and totals for this level
            push IP onto stack

        case: account
            pick up account info, insert into account IP

        case: transaction
            increment counter for debit or credit in IP
                currently at head of stack
            add amount to debit or credit total in IP
                currently at head of stack

        case: close bracket
            pop IP off stack
            roll counters and totals in this IP into IP
                currently at top of stack, if there is one
            output IP which was just popped off stack
    end cases
```

Фигура 9.4

Когда мы говорим «создать IP» в приведенной выше логике, мы можем просто использовать входящий IP, если в начале группы есть характерный тип. Имейте в виду, однако, что IP должен иметь поля данных для totals. Самый очевидный метод — создать контрольный IP, скопировать поля, такие как идентификаторы, из входящего IP (часто это тот, что идёт после открытой скобки) в контрольный IP, сохранить контрольный IP и отбросить исходный входящий IP. Однако более быстрый метод, который иногда можно использовать, заключается в том, чтобы входящие данные помещались в более крупный IP в то время, когда они считываются приложением. Затем его можно сразу сложить, без утомительной последовательности «создать новый, скопировать, уничтожить старый».

Теперь, когда у нас есть контрольные IP, что мы будем использовать в качестве стека? В AMPS был механизм стека специально для такой логики, который на самом деле был своего рода соединением (которое было присоединено только к одному концу, как [cul de sac](<https://en.wikipedia.org/wiki/Dead_end_(street)>) в городе). В более поздних версиях DFDM не было механизмов стека, но, поскольку мы имеем дело только с одним компонентом, было достаточно просто настроить массив дескрипторов IP в рабочей памяти процесса, а также "пушить" и "попать" (базовые операции со [стеком](<https://en.wikipedia.org/wiki/Stack_(abstract_data_type)>)) путем увеличения или уменьшения индекса массива. Однако мне нравятся стеки, и в следующей главе _мы увидим поразительное сходство между тем, как компоненты анализируют свои входные потоки, и тем, как компиляторы анализируют свои входные данные_ - в обоих случаях **стеки являются естественным механизмом отслеживания вложенных структур**. Соответственно, мы предоставили механизм стека в THREADS.

Вы, возможно, заметили, что на рисунках `9.3` и `9.4` не было знакомого «do while receive has not reached end of data» — это потому, что они написаны в стиле, который предполагает, что они завершают выполнение после обработки каждого IP. В FBP неактивный процесс будет вызываться в следующий раз, когда IP прибывает на любой из его входных портов, поэтому этот тип компонента будет вызываться один раз для каждого входящего IP. Как следствие, он не может поддерживать непрерывность между несколькими IP, но здесь на сцену и выходит стек. **Поскольку стек находится за пределами локального хранилища процесса, непрерывность может поддерживаться при вызовах с использованием стека**. Этот стиль компонента называется «non-looper», в отличие от компонентов, написанных в стиле «do while receive has not reached end of data», которые называются "loopers". Это не определяемый извне атрибут компонента, это зависит от того, когда и как часто компонент решает завершить обработку — до тех пор, пока есть данные для обработки, они будут продолжать вызываться повторно.
